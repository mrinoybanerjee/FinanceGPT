{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FinanceGPT: Using RAG Based LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python-dotenv could not parse statement starting at line 3\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load the environment variables\n",
    "load_dotenv()\n",
    "\n",
    "MONGODB_CONNECTION_STRING = os.getenv(\"MONGODB_URI\")\n",
    "MONGODB_DATABASE = os.getenv(\"MONGODB_DATABASE\")\n",
    "MONGODB_COLLECTION = os.getenv(\"MONGODB_COLLECTION\")\n",
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "REPLICATE_API_KEY = os.getenv(\"REPLICATE_API_TOKEN\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean reddit personal finance corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text, remove_headers_until=4):\n",
    "    \"\"\"\n",
    "    Clean the input text by removing header lines, normalizing whitespace,\n",
    "    and converting to lowercase.\n",
    "    \n",
    "    Args:\n",
    "    text (str): The input text to clean.\n",
    "    remove_headers_until (int): Number of initial lines to remove as headers.\n",
    "    \n",
    "    Returns:\n",
    "    str: The cleaned text.\n",
    "    \"\"\"\n",
    "    # Split text into lines and remove header lines\n",
    "    lines = text.splitlines()\n",
    "    cleaned_lines = lines[remove_headers_until:]\n",
    "    \n",
    "    # Join lines back and normalize text\n",
    "    cleaned_text = \"\\n\".join(cleaned_lines).strip().lower()\n",
    "    \n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Personal finance books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import fitz  # PyMuPDF\n",
    "\n",
    "# Function to preprocess and clean text\n",
    "def preprocess_text_mupdf(text):\n",
    "    text = re.sub(r'\\n\\s*\\n', '\\n', text)  # Remove empty lines\n",
    "    text = re.sub(r'[^A-Za-z0-9.,;:!?()\\'\\\"\\n]+', ' ', text)  # Remove special characters but keep punctuation\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Replace multiple spaces with single space\n",
    "    return text.strip()\n",
    "\n",
    "raw_path = '/Users/mrinoyb2/git/FinanceGPT/data/pf_books/pdfs'\n",
    "clean_text_dir = '/Users/mrinoyb2/git/FinanceGPT/data/pf_books/clean'\n",
    "os.makedirs(clean_text_dir, exist_ok=True)\n",
    "\n",
    "# Process each PDF file in the extracted directory\n",
    "for root, dirs, files in os.walk(raw_path):\n",
    "    for file in files:\n",
    "        if file.endswith('.pdf'):\n",
    "            pdf_path = os.path.join(root, file)\n",
    "            pdf_document = fitz.open(pdf_path)\n",
    "\n",
    "            cleaned_text_mupdf = \"\"\n",
    "            for page_number in range(pdf_document.page_count):\n",
    "                page = pdf_document.load_page(page_number)\n",
    "                text = page.get_text()\n",
    "                cleaned_text_mupdf += preprocess_text_mupdf(text)\n",
    "\n",
    "            pdf_document.close()\n",
    "\n",
    "            # Save the cleaned text to a corresponding file\n",
    "            clean_text_path = os.path.join(clean_text_dir, os.path.splitext(file)[0] + '.txt')\n",
    "            with open(clean_text_path, 'w') as file:\n",
    "                file.write(cleaned_text_mupdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store chunks in MongoDB database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/mrinoyb2/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chunks stored in MongoDB: 11597\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pymongo\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "nltk.download('punkt')  # Download the Punkt tokenizer models\n",
    "\n",
    "\n",
    "# Connect to MongoDB\n",
    "client = pymongo.MongoClient(MONGODB_CONNECTION_STRING)\n",
    "db = client[MONGODB_DATABASE]\n",
    "collection = db[MONGODB_COLLECTION]\n",
    "\n",
    "# Function to chunk text by sentence\n",
    "def chunk_by_sentence(text):\n",
    "    \"\"\"\n",
    "    Improved function to chunk text by sentence using NLTK's sent_tokenize.\n",
    "    \n",
    "    Args:\n",
    "    text (str): The input text to chunk.\n",
    "    \n",
    "    Returns:\n",
    "    list: A list of sentences extracted from the input text.\n",
    "    \"\"\"\n",
    "    sentences = sent_tokenize(text)\n",
    "    return [sentence.strip() for sentence in sentences]\n",
    "\n",
    "# Path to the directory containing cleaned text files\n",
    "clean_text_dir = '/Users/mrinoyb2/git/FinanceGPT/data/All_texts'\n",
    "\n",
    "# Initialize a counter for unique MongoDB document IDs\n",
    "doc_id = 0\n",
    "\n",
    "# Iterate through each cleaned text file\n",
    "for file_name in os.listdir(clean_text_dir):\n",
    "    if file_name.endswith('.txt'):\n",
    "        file_path = os.path.join(clean_text_dir, file_name)\n",
    "\n",
    "        # Read the cleaned text from the file\n",
    "        with open(file_path, 'r') as file:\n",
    "            cleaned_text = file.read()\n",
    "\n",
    "        # Chunk the text\n",
    "        chunks = chunk_by_sentence(cleaned_text)\n",
    "\n",
    "        # Store chunks in MongoDB\n",
    "        for chunk in chunks:\n",
    "            # Create a document for each chunk\n",
    "            document = {\"_id\": doc_id, \"text\": chunk}\n",
    "            # Insert the document into the collection\n",
    "            collection.insert_one(document)\n",
    "            # Increment the doc_id for the next document\n",
    "            doc_id += 1\n",
    "\n",
    "print(f\"Total chunks stored in MongoDB: {doc_id}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': 0, 'text': 'the-usd-inr-pair\\n4.1 – the contract\\nwe make an extremely critical assumption at this stage – we will assume you are familiar with how future and options contracts work.', 'embedding': [-0.07872910797595978, 0.021708624437451363, -0.032432589679956436, 0.007473672740161419, -0.009834710508584976, -0.029723696410655975, -0.018552307039499283, 0.07715348154306412, 0.042258694767951965, 0.005934880115091801, 0.018288377672433853, 0.001879948889836669, -0.049384526908397675, 0.06370308250188828, 0.021877873688936234, -0.0008213091059587896, -0.02738482505083084, -0.12179657071828842, -0.04125848412513733, 0.03758013993501663, -0.05928162485361099, -0.08154621720314026, -0.04822477325797081, -0.034306205809116364, 0.03087666630744934, -0.08323254436254501, 0.007064621429890394, -0.01629713550209999, 0.00443514296784997, -0.018304815515875816, -0.02091113105416298, 0.11329317837953568, -0.0031237865332514048, -0.06396238505840302, -0.05167407914996147, -0.012983483262360096, 0.04193238914012909, -0.06702720373868942, 0.010433712974190712, -8.40151114971377e-05, 0.010664878413081169, -0.021921394392848015, 0.022158464416861534, -0.0011883010156452656, -0.06568661332130432, 0.016516193747520447, 0.023006141185760498, 0.021296154707670212, -0.02512090466916561, -0.00037037619040347636, 0.05135498195886612, 0.07344194501638412, 0.012782484292984009, -0.034547992050647736, 0.02475481852889061, 0.02111036889255047, -0.0758167952299118, 0.02973480336368084, -0.043906815350055695, 0.06285174190998077, 0.02219606563448906, 0.007826201617717743, -0.03288297727704048, 0.046639006584882736, -0.0009011896909214556, 0.023182854056358337, 0.06644294410943985, -0.0012940281303599477, -0.08633831143379211, 0.03744960203766823, -0.01800273172557354, -0.052048880606889725, -0.018167119473218918, -0.012582020834088326, 0.04237452149391174, 0.011471481993794441, 0.09110970050096512, 0.014405468478798866, 0.029135994613170624, -0.059486839920282364, 0.037426628172397614, -0.01497059315443039, -0.032738495618104935, -0.09680771082639694, 0.03365970402956009, 0.0033579389564692974, 0.03258245810866356, -0.018290217965841293, 0.07807263731956482, -0.012477499432861805, 0.016238801181316376, -0.1026764065027237, -0.009452207013964653, 0.0010600310051813722, -0.014493058435618877, 0.11348189413547516, -0.04350944235920906, 0.04537981003522873, 0.05234629660844803, 0.014303363859653473, 0.05448416620492935, -0.04505372419953346, -0.025643303990364075, 0.007895299233496189, -0.0440974086523056, -0.05376744642853737, -0.0015145193319767714, -0.025863248854875565, 0.07965834438800812, 0.08312052488327026, -0.03503374382853508, -0.059947457164525986, 0.02852361649274826, 0.012132375501096249, -0.10483843833208084, 0.01069991197437048, -0.03789558261632919, 0.02706589736044407, 0.09509313106536865, -0.09740439802408218, -0.055429644882678986, 0.03530045226216316, -0.01986369863152504, -0.024142539128661156, -0.12559041380882263, -0.021485434845089912, 0.014417100697755814, -3.2943041837382445e-33, -0.035270508378744125, 0.06174827739596367, 0.03174954652786255, -0.05597676336765289, -0.046582434326410294, 0.0006766311125829816, -0.0335022434592247, 0.0701054260134697, -0.04156297817826271, 0.017458999529480934, -0.010683668777346611, -0.03857189416885376, 0.03694446012377739, 0.10341840982437134, 0.021420370787382126, -0.04791105166077614, -0.014352694153785706, 0.014033440500497818, 0.06583549827337265, 0.06231074407696724, 0.037660833448171616, 0.052306052297353745, -0.04139682278037071, -0.009198356419801712, 0.04693392291665077, 0.044954776763916016, 0.026516402140259743, -0.04879815876483917, 0.033832598477602005, -0.027562551200389862, -0.05009821429848671, 0.08455868065357208, -0.09397441148757935, -0.014179805293679237, -0.03164796158671379, 0.04620376229286194, -0.030646242201328278, 0.011330598033964634, -0.08045245707035065, -0.031042834743857384, -0.014195696450769901, 0.05400453507900238, -0.09887978434562683, 0.01705857180058956, 0.07395744323730469, -0.0020254054106771946, 0.07620343565940857, 0.04370876029133797, -0.025953708216547966, -0.003252469003200531, -0.10725206136703491, 0.06773402541875839, -0.05166272446513176, -0.014917007647454739, 0.009673008695244789, -0.03270421922206879, 0.006193848326802254, -0.008183213882148266, -0.009799188934266567, 0.03015863336622715, -0.004566470626741648, -0.05676748603582382, -0.01875883713364601, -0.022041810676455498, -0.090239018201828, 0.1017436608672142, -0.0744536817073822, -0.08174093067646027, -0.020421558991074562, -0.025355657562613487, -0.057364579290151596, 0.020383495837450027, 0.028730496764183044, -0.010582058690488338, 0.009365958161652088, -0.00800212100148201, 0.043770067393779755, -0.02490735985338688, 0.08511623740196228, 0.0065721007995307446, -0.12499263882637024, 0.05344628542661667, 0.08136456459760666, 0.10281084477901459, 0.004052501637488604, 0.02965855598449707, 0.0701068565249443, 0.010848389938473701, 0.12610553205013275, 0.08092528581619263, -0.00020865708938799798, -0.0127562889829278, -0.05392023175954819, 0.007973109371960163, 0.10904359072446823, -1.0577539897435463e-33, -0.028311770409345627, 0.05584254115819931, 0.021835967898368835, 0.12209863215684891, -0.010765111073851585, 0.00951902661472559, 0.023906048387289047, 0.06313581764698029, 0.10399459302425385, -0.00245482730679214, 0.0627591460943222, -0.008023335598409176, 0.002976881805807352, -0.013852160423994064, 0.03769567981362343, -0.04451882466673851, -0.12506358325481415, -0.08370596915483475, 0.026512855663895607, 0.025589708238840103, 0.035246592015028, -0.009436598978936672, -0.05572769418358803, 0.09631318598985672, -0.00616323109716177, -0.002797376364469528, 0.051388148218393326, -0.06257190555334091, -0.049846846610307693, 0.003355736844241619, -0.029063962399959564, -0.020467747002840042, -0.09865192323923111, 0.062134940177202225, -0.016076596453785896, 0.014379594475030899, 0.0160591471940279, 0.03134191781282425, -0.028763189911842346, 0.05520442873239517, -0.03938283026218414, 0.023732857778668404, -0.003253260627388954, 0.07003043591976166, -0.04176779091358185, -0.04191434755921364, 0.024416161701083183, 0.05241227149963379, 0.012411823496222496, -0.025335168465971947, 0.045365262776613235, 0.050793856382369995, -0.06667216867208481, -0.06410735845565796, -0.04109635576605797, -0.053023699671030045, -0.014809333719313145, -0.05070292204618454, 0.03963543102145195, 0.058921631425619125, 0.03140958026051521, 0.017474567517638206, 0.09259574115276337, 0.017816558480262756, -0.008431725203990936, -0.013201969675719738, -0.022861113771796227, -0.014750896021723747, 0.09010525047779083, -0.014177902601659298, 0.023175543174147606, -0.1306477040052414, 0.01749005727469921, -0.03658643364906311, 0.08757353574037552, -0.01740330643951893, -0.04868369549512863, -0.132295161485672, 0.09290079772472382, 0.01153856236487627, -0.03911205008625984, 0.04298935458064079, 0.02389194443821907, -0.02285062149167061, 0.02451506070792675, 0.014519666321575642, -0.018304821103811264, 0.0551578551530838, 0.04924198240041733, 0.0034612950403243303, -0.07144518196582794, 0.04372468963265419, -0.03327024728059769, 0.04076751694083214, -0.11809597909450531, -3.753478594603621e-08, 0.009661919437348843, -0.045874662697315216, 0.027280207723379135, 0.0073710475116968155, -0.060056693851947784, 0.006299044005572796, 0.05123692378401756, 0.029257526621222496, 0.024949299171566963, 0.06850514560937881, 0.025745360180735588, -0.023878514766693115, -0.05418011546134949, -0.04926884546875954, 0.036839939653873444, 0.05433209240436554, 0.032781776040792465, 0.03902057558298111, -0.08535182476043701, -0.01811310090124607, -0.06516092270612717, 0.03704451024532318, -0.03642580658197403, -0.1294959932565689, 0.027185747399926186, 0.03761332109570503, -0.010976734571158886, 0.13937442004680634, -0.04688720032572746, 0.06827002018690109, -0.03034454770386219, 0.032453905791044235, -0.012033653445541859, -0.027678625658154488, -0.008213816210627556, 0.00018856603128369898, -0.0280512273311615, 0.0664638802409172, 0.037529390305280685, -0.023987455293536186, -0.04903065785765648, -0.0691765546798706, -0.10317511111497879, 0.036449458450078964, 0.010501897893846035, -0.010324983857572079, -0.08581932634115219, -0.02819431759417057, -0.030060796067118645, -0.059271976351737976, -0.08686064183712006, 0.03938544914126396, 0.028950592502951622, 0.013753846287727356, 0.07621841132640839, 0.00387261132709682, -0.0920550748705864, -0.025166425853967667, 0.019096171483397484, -0.0062835924327373505, -0.051000531762838364, -0.13642947375774384, -0.024441765621304512, 0.02004142478108406]}\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import pymongo\n",
    "\n",
    "# Connect to MongoDB\n",
    "client = pymongo.MongoClient(MONGODB_CONNECTION_STRING)\n",
    "db = client[MONGODB_DATABASE]\n",
    "chunks_collection = db[MONGODB_COLLECTION]\n",
    "\n",
    "# Load the sentence transformer model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Function to update documents with embeddings\n",
    "def update_documents_with_embeddings():\n",
    "    for document in chunks_collection.find():\n",
    "        # Generate embedding\n",
    "        embedding = model.encode(document['text'], convert_to_tensor=False)\n",
    "        # Update document with embedding\n",
    "        chunks_collection.update_one({'_id': document['_id']}, {'$set': {'embedding': embedding.tolist()}})\n",
    "\n",
    "# Uncomment the following line to run the embedding update\n",
    "update_documents_with_embeddings()\n",
    "\n",
    "# Check the first document to see if the embedding was added\n",
    "print(chunks_collection.find_one())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semantic search retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result 1 (Score: 0.667): |\n",
      "index funds\n",
      "|\n",
      "exchange-traded funds\n",
      "|end of the day nav\n",
      "|real-time pricing....\n",
      "Result 2 (Score: 0.647): with etfs, you can express tactical strategies better than index funds because you can’t buy and sell index funds immediately....\n",
      "Result 3 (Score: 0.636): It is a mutual fund....\n",
      "Result 4 (Score: 0.634): today, it’s a no-brainer to look at index funds in the large-cap space....\n",
      "Result 5 (Score: 0.611): to recap, a mutual fund is a pooled investment vehicle that collects the money from various investors, invests and manages that money on their behalf....\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import pymongo\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cosine\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Connect to MongoDB\n",
    "client = pymongo.MongoClient(MONGODB_CONNECTION_STRING)\n",
    "db = client[MONGODB_DATABASE]\n",
    "chunks_collection = db[MONGODB_COLLECTION]\n",
    "\n",
    "# Function to perform semantic search\n",
    "def semantic_search(query, top_k=5):\n",
    "    # Encode the query using the provided embedding model\n",
    "    embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    query_embedding = embedding_model.encode(query, convert_to_tensor=False)\n",
    "    \n",
    "    # Retrieve all embeddings from MongoDB and calculate similarity\n",
    "    similarities = []\n",
    "    for document in chunks_collection.find():\n",
    "        doc_embedding = np.array(document['embedding'])\n",
    "        # Use scikit-learn's cosine_similarity function to calculate the cosine distance\n",
    "        similarity = cosine_similarity([query_embedding], [doc_embedding])[0][0]\n",
    "        # Store document ID and similarity score. Remove documents with same similarity scores.\n",
    "        if document['text'] not in [x[2] for x in similarities] and similarity not in [x[1] for x in similarities]:\n",
    "            similarities.append((document['_id'], similarity, document['text']))\n",
    "    \n",
    "    # Sort by similarity score in descending order and remove duplicates\n",
    "    similarities = sorted(similarities, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Return top_k most similar documents\n",
    "    return similarities[:top_k]\n",
    "\n",
    "# Example usage\n",
    "query = \"What are index funds?\"\n",
    "results = semantic_search(query)\n",
    "for idx, (doc_id, similarity, text) in enumerate(results, start=1):\n",
    "    print(f\"Result {idx} (Score: {similarity:.3f}): {text}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up Gemini Pro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import textwrap\n",
    "\n",
    "import google.generativeai as genai\n",
    "\n",
    "from IPython.display import display\n",
    "from IPython.display import Markdown\n",
    "\n",
    "\n",
    "def to_markdown(text):\n",
    "  text = text.replace('•', '  *')\n",
    "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or use `os.getenv('GOOGLE_API_KEY')` to fetch an environment variable.\n",
    "\n",
    "genai.configure(api_key=GEMINI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/gemini-1.0-pro\n",
      "models/gemini-1.0-pro-001\n",
      "models/gemini-1.0-pro-latest\n",
      "models/gemini-1.0-pro-vision-latest\n",
      "models/gemini-pro\n",
      "models/gemini-pro-vision\n"
     ]
    }
   ],
   "source": [
    "for m in genai.list_models():\n",
    "  if 'generateContent' in m.supported_generation_methods:\n",
    "    print(m.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "Age = 25\n",
    "Annual_Income = 10000\n",
    "Employment = \"Full Time\"\n",
    "Debt = 15000\n",
    "Assets = 10000\n",
    "Credit_Score = 500\n",
    "\n",
    "Financial_Goal = \"Saving for a house\"\n",
    "Risk_Tolerance = \"High\"\n",
    "Time_Horizon = \"Short Term\"\n",
    "Life_Event = \"Buying a car\"\n",
    "\n",
    "# Create dictionary to store user input\n",
    "user_input = {\n",
    "    \"Age\": Age,\n",
    "    \"Income\": Annual_Income,\n",
    "    \"Employment\": Employment,\n",
    "    \"Debt\": Debt,\n",
    "    \"Assets\": Assets,\n",
    "    \"Credit_Score\": Credit_Score,\n",
    "    \"Financial_Goal\": Financial_Goal,\n",
    "    \"Risk_Tolerance\": Risk_Tolerance,\n",
    "    \"Time_Horizon\": Time_Horizon,\n",
    "    \"Life_Event\": Life_Event\n",
    "}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect LLM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import replicate\n",
    "from replicate.client import Client\n",
    "# Function to generate an answer using RAG enabled Gemini pro\n",
    "def generate_RAG_answer(question, user_input, max_context_length=20000):\n",
    "    # Assume semantic_search is defined and returns relevant context as a single string\n",
    "    context_results = semantic_search(question, top_k=5)\n",
    "    # Combine the top 5 context results into a single string\n",
    "    context = \" \".join([result[2] for result in context_results])\n",
    "    # Truncate context if it exceeds the maximum length\n",
    "    if len(context) > max_context_length:\n",
    "        context = context[:max_context_length]\n",
    "\n",
    "    rag_prompt = f\"\"\"[INST]\n",
    "    Persona: You are a highly knowledgeable and personable financial advisor with access to a vast database of financial resources. You prioritize clear, actionable advice tailored to the user's unique situation and goals.\n",
    "    \n",
    "    Context: {context}\n",
    "\n",
    "    Example 1:\n",
    "    Question: \"I'm 30 years old making $60,000 a year with no debt and $20,000 in savings. How can I start investing for retirement?\"\n",
    "    User Context: Financial Situation: Age: 30, income: 60000, employment: \"Full Time\", debt: 0, assets: 20000. Financial Goals: Long-term (retirement). Risk Tolerance: Moderate. Life Events: N/A.\n",
    "    Answer: \"Given your stable income, no debt, and a moderate risk tolerance, you're in a great position to start investing for retirement. A balanced mix of stocks and bonds in a tax-advantaged retirement account like a Roth IRA would be a good start. Consider allocating 70% to a diversified stock fund and 30% to bonds. Adjust the allocation as you age or as your risk tolerance changes.\"\n",
    "\n",
    "    Example 2:\n",
    "    Question: \"I'm 22, just started my first job earning $45,000, and have $10,000 in student loans. What's my best strategy for saving?\"\n",
    "    User Context: Financial Situation: Age: 22, income: 45000, employment: \"Full Time\", debt: 10000, assets: 5000. Financial Goals: Short-term (emergency fund), mid-term (debt repayment). Risk Tolerance: Low. Life Events: Starting first job.\n",
    "    Answer: \"Starting with your student loans and building an emergency fund are your first steps. Aim to pay more than the minimum on your loans to reduce interest costs over time. For your emergency fund, start by saving three months' worth of expenses in a high-yield savings account, gradually increasing to six months. Once these goals are met, you can start saving for other short- and mid-term goals.\"\n",
    "\n",
    "    Your Question: \"{question}\"\n",
    "    Your User Context: Financial Situation: Age: {user_input['Age']}, income: {user_input['Income']}, employment: \"{user_input['Employment']}\", \n",
    "    debt: {user_input['Debt']}, assets: {user_input['Assets']}, credit score: {user_input['Credit_Score']}, Financial Goals: {user_input['Financial_Goal']}, \n",
    "    Risk Tolerance: \"{user_input['Risk_Tolerance']}\", Time Horizon: \"{user_input['Time_Horizon']}\", Life Events: \"{user_input['Life_Event']}\".\n",
    "\n",
    "    Response Style: \n",
    "    * Clarity: Explain complex concepts in simple terms.\n",
    "    * Actionable: Provide specific recommendations and next steps. \n",
    "    * Personalization: Tailor the advice to the user's situation and goals.\n",
    "    * Transparency: Acknowledge limitations and suggest further resources if needed.\n",
    "    [/INST]\"\"\"\n",
    "\n",
    "    client = Client(api_token=REPLICATE_API_KEY)\n",
    "\n",
    "    # Generate the answer using LLama2 from Replicate\n",
    "    # The mistralai/mixtral-8x7b-instruct-v0.1 model can stream output as it's running.\n",
    "    for event in client.stream(\n",
    "        \"mistralai/mixtral-8x7b-instruct-v0.1\",\n",
    "        input={\n",
    "            \"top_k\": 50,\n",
    "            \"top_p\": 1,\n",
    "            \"prompt\": rag_prompt,\n",
    "            \"temperature\": 0.5,\n",
    "            \"max_new_tokens\": 1024,\n",
    "            \"prompt_template\": \"<s>[INST] {prompt} [/INST] \",\n",
    "            \"presence_penalty\": 0,\n",
    "            \"frequency_penalty\": 0\n",
    "        },\n",
    "    ):\n",
    "        print(str(event), end=\"\")\n",
    "\n",
    "# Function to generate an answer using Gemini pro\n",
    "def generate_non_RAG_answer(question, user_input):\n",
    "    # Assume semantic_search is defined and returns relevant context as a single string\n",
    "    non_rag_prompt = f\"\"\"[INST]\n",
    "    Persona: You are a highly knowledgeable and personable financial advisor with access to a vast database of financial resources. You prioritize clear, actionable advice tailored to the user's unique situation and goals.\n",
    "\n",
    "    Example 1:\n",
    "    Question: \"I'm 30 years old making $60,000 a year with no debt and $20,000 in savings. How can I start investing for retirement?\"\n",
    "    User Context: Financial Situation: Age: 30, income: 60000, employment: \"Full Time\", debt: 0, assets: 20000. Financial Goals: Long-term (retirement). Risk Tolerance: Moderate. Life Events: N/A.\n",
    "    Answer: \"Given your stable income, no debt, and a moderate risk tolerance, you're in a great position to start investing for retirement. A balanced mix of stocks and bonds in a tax-advantaged retirement account like a Roth IRA would be a good start. Consider allocating 70% to a diversified stock fund and 30% to bonds. Adjust the allocation as you age or as your risk tolerance changes.\"\n",
    "\n",
    "    Example 2:\n",
    "    Question: \"I'm 22, just started my first job earning $45,000, and have $10,000 in student loans. What's my best strategy for saving?\"\n",
    "    User Context: Financial Situation: Age: 22, income: 45000, employment: \"Full Time\", debt: 10000, assets: 5000. Financial Goals: Short-term (emergency fund), mid-term (debt repayment). Risk Tolerance: Low. Life Events: Starting first job.\n",
    "    Answer: \"Based on your situation, you should first pay off your student loans. If you set aside $500 per month, you can pay off your student loans in 20 months. After that, you should start building an emergency fund. You should aim to save at least 3 months of living expenses. Once you have your emergency fund, you can start investing in a low-cost index fund.\"\n",
    "\n",
    "    Example 3:\n",
    "    Question: \"I'm 25, just started my first job earning $20,000, and have $10,000 in student loans. I would like to buy a house in the next 12 months, what's the best strategy for saving?\"\n",
    "    User Context: Financial Situation: Age: 25, income: 20,000, employment: \"Full Time\", debt: 10000, assets: 5000, credit_score = 500. Financial Goals: Short-term (emergency fund), mid-term (debt repayment). Risk Tolerance: Low. Life Events: Starting first job.\n",
    "    Answer: \"Based on your situation, you are not ready to buy a house yet. You should first pay off your student loans and focus on improving your credit score. In order to pay your student loans, set aside $500 per month, you can pay off your student loans in 20 months. After that, you should start building an emergency fund. You should aim to save at least 3 months of living expenses. Once you have your emergency fund, you can start investing in a low-cost index fund. Once you have paid off your student loans, improved your credit score, and saved for an emergency fund, you can start saving for a house.\"\n",
    "\n",
    "    \n",
    "    Your Question: \"{question}\"\n",
    "    Your User Context: Financial Situation: Age: {user_input['Age']}, income: {user_input['Income']}, employment: \"{user_input['Employment']}\", \n",
    "    debt: {user_input['Debt']}, assets: {user_input['Assets']}, credit score: {user_input['Credit_Score']}, Financial Goals: {user_input['Financial_Goal']}, \n",
    "    Risk Tolerance: \"{user_input['Risk_Tolerance']}\", Time Horizon: \"{user_input['Time_Horizon']}\", Life Events: \"{user_input['Life_Event']}\".\n",
    "\n",
    "    Response Style: \n",
    "    * Clarity: Explain complex concepts in simple terms.\n",
    "    * Actionable: Provide specific recommendations and next steps. \n",
    "    * Personalization: Tailor the advice to the user's situation and goals.\n",
    "    * Transparency: Acknowledge limitations and suggest further resources if needed.\n",
    "    [/INST]\"\"\"\n",
    "    model = genai.GenerativeModel('gemini-1.0-pro-latest')\n",
    "    response = model.generate_content(non_rag_prompt)\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: once you have, invest in low-cost broad market index funds and move on with your life. today, it’s a no-brainer to look at index funds in the large-cap space. but if you are lazy like me and want to make as fewer choices as possible, then index funds are a better choice. |\n",
      "index funds\n",
      "|\n",
      "exchange-traded funds\n",
      "|end of the day nav\n",
      "|real-time pricing. with etfs, you can express tactical strategies better than index funds because you can’t buy and sell index funds immediately.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Sure, I'd be happy to help explain index funds and provide some guidance based on your financial situation!\n",
      "\n",
      "Index funds are a type of investment vehicle that aims to track the performance of a specific market index, such as the S&P 500. By investing in an index fund, you're essentially buying a diversified portfolio of stocks or bonds that mirrors the holdings of the underlying index. This can be a simple and cost-effective way to invest, as index funds typically have lower expense ratios than actively managed funds.\n",
      "\n",
      "Based on your financial situation and goals, here are some specific recommendations:\n",
      "\n",
      "* Given your high risk tolerance and short-term time horizon, you may be willing to consider investments beyond just index funds. However, since you're currently saving for a house and have a relatively low credit score, it's important to prioritize building up your savings and improving your credit profile before taking on too much investment risk.\n",
      "* With that in mind, an index fund can still be a good option for you, especially if you're looking for a simple and low-cost way to invest. You might consider a broad-market index fund that tracks the performance of the overall stock market, such as the Vanguard Total Stock Market Index Fund. This can provide exposure to a wide range of stocks and help you build a diversified portfolio.\n",
      "* Another option to consider is a low-cost target date fund, which is designed to automatically adjust the mix of stocks and bonds in your portfolio based on your expected retirement date. For example, if you're planning to buy a house in the next few years and then save for retirement after that, you might choose a target date fund with a date that's a few years after your expected home purchase.\n",
      "* Whatever investment vehicle you choose, it's important to remember that all investments come with some level of risk, and there's no guarantee of positive returns. Be sure to do your own research and consider seeking advice from a financial professional before making any investment decisions.\n",
      "\n",
      "I hope this helps! Let me know if you have any other questions or if there's anything else I can assist you with."
     ]
    }
   ],
   "source": [
    "# Example query\n",
    "query = \"What are index funds? Should I invest in them?\"\n",
    "generate_RAG_answer(query, user_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**What are index funds?**\n",
      "\n",
      "An index fund is a type of mutual fund that tracks a specific market index, like the S&P 500 or the Nasdaq Composite. This means that the fund holds all of the stocks that are in the index, in the same proportions.\n",
      "\n",
      "Index funds are popular because they are:\n",
      "\n",
      "* **Low-cost:** Index funds typically have lower fees than actively managed mutual funds.\n",
      "* **Diversified:** Index funds hold a large number of stocks, which helps to reduce risk.\n",
      "* **Transparent:** Index funds are required to disclose their holdings, so you know exactly what you're investing in.\n",
      "\n",
      "**Are index funds right for you?**\n",
      "\n",
      "Index funds can be a good investment for investors of all ages and risk tolerances. However, they may be particularly suitable for:\n",
      "\n",
      "* **Investors who are new to investing.** Index funds are a simple and easy way to get started with investing.\n",
      "* **Investors who do not have a lot of time to research individual stocks.** Index funds allow you to invest in a diversified portfolio of stocks without having to do a lot of research.\n",
      "* **Investors who are risk-averse.** Index funds are less risky than investing in individual stocks.\n",
      "\n",
      "**How to invest in index funds**\n",
      "\n",
      "You can invest in index funds through a variety of investment accounts, including:\n",
      "\n",
      "* **401(k) plans**\n",
      "* **IRAs**\n",
      "* **Brokerage accounts**\n",
      "\n",
      "When choosing an index fund, it is important to compare the fees, the performance, and the investment objectives of the fund.\n",
      "\n",
      "**Additional resources**\n",
      "\n",
      "* [Index Funds Explained](https://www.investopedia.com/articles/basics/03/indexfund.asp)\n",
      "* [Vanguard Index Funds](https://investor.vanguard.com/investor-resources/education/understanding-investment-types/index-funds)\n",
      "* [Fidelity Index Funds](https://www.fidelity.com/learning-center/investment-products/mutual-funds/index-funds)\n"
     ]
    }
   ],
   "source": [
    "# Example query\n",
    "query = \"What are index funds?\"\n",
    "non_rag_answer = generate_non_RAG_answer(query, user_input)\n",
    "\n",
    "print(non_rag_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating RAG vs Non-RAG Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to quantify this, I will take the following steps:\n",
    "1. Think of a query which has a well defined answer in the book.\n",
    "2. Find the true answer to a query from the actual source (book pdf). \n",
    "3. Then pass the query through the RAG based LLM and the regular LLM.\n",
    "4. Save both generated answers along with the true answer and find word embeddings for each. \n",
    "5. Finally, compare the word embeddings of the true answer with the RAG vs Non-RAG based LLM word embeddings using cosine similarity. \n",
    "\n",
    "Following these steps will help quantify the performace and accuracy of information in the two answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Best practices for repaying loans\"\n",
    "\n",
    "# True Answer from the Huberman Lab Newsletter\n",
    "true_answer = \"\"\"\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing functions to evaluate performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def get_embedding(text):\n",
    "    \"\"\"\n",
    "    Generate an embedding for a given text.\n",
    "\n",
    "    Args:\n",
    "    - text (str): The input text.\n",
    "    \n",
    "    Returns:\n",
    "    - The sentence embedding.\n",
    "    \"\"\"\n",
    "    # Load the sentence transformer model\n",
    "    model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    # Generate the sentence embeddings\n",
    "    embeddings = model.encode(text, convert_to_tensor=False)\n",
    "    return embeddings\n",
    "\n",
    "\n",
    "def calculate_cosine_similarity(embedding1, embedding2):\n",
    "    \"\"\"\n",
    "    Calculate the cosine similarity between two embeddings.\n",
    "\n",
    "    Args:\n",
    "    - embedding1 (torch.Tensor): The first embedding.\n",
    "    - embedding2 (torch.Tensor): The second embedding.\n",
    "\n",
    "    Returns:\n",
    "    - The cosine similarity score.\n",
    "    \"\"\"\n",
    "    # Calculate the cosine similarity\n",
    "    similarity = 1 - cosine(embedding1, embedding2)\n",
    "    return similarity\n",
    "\n",
    "\n",
    "def calculate_similarity_scores(true_answer, rag_answer, non_rag_answer):\n",
    "    \"\"\"\n",
    "    Calculate the cosine similarity scores between the true answer and both RAG-based and non-RAG-based answers.\n",
    "\n",
    "    Args:\n",
    "    - true_answer (str): The true answer text.\n",
    "    - rag_answer (str): The RAG-based model's answer text.\n",
    "    - non_rag_answer (str): The non-RAG-based model's answer text.\n",
    "\n",
    "    Returns:\n",
    "    - A dictionary with cosine similarity scores.\n",
    "    \"\"\"\n",
    "    # Convert the answers to embeddings\n",
    "    true_answer_embedding = get_embedding(true_answer)\n",
    "    rag_answer_embedding = get_embedding(rag_answer)\n",
    "    non_rag_answer_embedding = get_embedding(non_rag_answer)\n",
    "    \n",
    "    # Calculate cosine similarity scores\n",
    "    rag_similarity = calculate_cosine_similarity(true_answer_embedding, rag_answer_embedding)\n",
    "    non_rag_similarity = calculate_cosine_similarity(true_answer_embedding, non_rag_answer_embedding)\n",
    "\n",
    "    \n",
    "    # Return the scores\n",
    "    return {\n",
    "        \"RAG Similarity Score\": rag_similarity,\n",
    "        \"Non-RAG Similarity Score\": non_rag_similarity\n",
    "    }\n",
    "\n",
    "\n",
    "# Calculate the similarity scores\n",
    "similarity_scores = calculate_similarity_scores(true_answer, rag_answer, non_rag_answer)\n",
    "print(similarity_scores)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
